{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción y Procesamiento Diario\n",
        "Procesa los datos históricos de ventas y genera métricas diarias por proveedor"
      ],
      "metadata": {
        "language": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"../utils/config\""
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Configuración\n",
        "batch_config = get_batch_config()\n",
        "processing_date = datetime.now().date() - timedelta(days=1)"
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer datos del día anterior\n",
        "df_sales = spark.read.table(\"raw_sales\")\\\n",
        "    .where(date_trunc('day', col('timestamp')) == processing_date)"
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular métricas diarias por proveedor\n",
        "df_daily_metrics = df_sales.groupBy(\n",
        "    date_trunc('day', col('timestamp')).alias('date'),\n",
        "    'provider_id',\n",
        "    'client_id'\n",
        ").agg(\n",
        "    count('*').alias('transaction_count'),\n",
        "    sum('amount').alias('total_amount'),\n",
        "    avg('amount').alias('avg_amount')\n",
        ")"
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir resultados en Delta Lake\n",
        "df_daily_metrics.write\\\n",
        "    .format('delta')\\\n",
        "    .mode(batch_config['write_mode'])\\\n",
        "    .partitionBy(*batch_config['partition_columns'])\\\n",
        "    .saveAsTable('daily_metrics')"
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular top clientes por proveedor\n",
        "df_top_clients = df_sales.groupBy(\n",
        "    'provider_id',\n",
        "    'client_id'\n",
        ").agg(\n",
        "    sum('amount').alias('total_amount')\n",
        ").orderBy(\n",
        "    'provider_id',\n",
        "    col('total_amount').desc()\n",
        ")"
      ],
      "metadata": {
        "language": "python"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir top clientes\n",
        "df_top_clients.write\\\n",
        "    .format('delta')\\\n",
        "    .mode('overwrite')\\\n",
        "    .saveAsTable('top_clients')\n",
        "\n",
        "# Optimizar tablas\n",
        "for table in ['daily_metrics', 'top_clients']:\n",
        "    spark.sql(f\"OPTIMIZE {table}\")\n",
        "    spark.sql(f\"VACUUM {table} RETAIN {batch_config['vacuum_retention']}\")"
      ],
      "metadata": {
        "language": "python"
      }
    }
  ],
  "metadata": {
    "name": "01_extract_daily_data",
    "notebookId": "extract_daily_data_notebook",
    "language_info": {
      "name": "python"
    }
  }
} 